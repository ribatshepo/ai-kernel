---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: aikernel-monitoring
  labels:
    app: prometheus
    app.kubernetes.io/part-of: ai-kernel
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      scrape_timeout: 10s
      evaluation_interval: 15s
      external_labels:
        cluster: 'aikernel'
        environment: 'production'

    # Alertmanager configuration
    alerting:
      alertmanagers:
        - static_configs:
            - targets:
              - alertmanager:9093

    # Load rules once and periodically evaluate them
    rule_files:
      - '/etc/prometheus/rules/*.yml'

    # Scrape configurations
    scrape_configs:
      # Prometheus itself
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']

      # Kubernetes API server
      - job_name: 'kubernetes-apiservers'
        kubernetes_sd_configs:
          - role: endpoints
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
            action: keep
            regex: default;kubernetes;https

      # Kubernetes nodes
      - job_name: 'kubernetes-nodes'
        kubernetes_sd_configs:
          - role: node
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)

      # Kubernetes pods
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: kubernetes_pod_name

      # PostgreSQL
      - job_name: 'postgres'
        static_configs:
          - targets: ['postgres-primary.aikernel-data:9187']
        relabel_configs:
          - source_labels: [__address__]
            target_label: instance
            replacement: 'postgres'

      # Redis
      - job_name: 'redis'
        static_configs:
          - targets: ['redis-master.aikernel-data:9121']
        relabel_configs:
          - source_labels: [__address__]
            target_label: instance
            replacement: 'redis'

      # Elasticsearch
      - job_name: 'elasticsearch'
        static_configs:
          - targets: ['elasticsearch.aikernel-data:9114']
        relabel_configs:
          - source_labels: [__address__]
            target_label: instance
            replacement: 'elasticsearch'

  alert_rules.yml: |
    groups:
      - name: infrastructure_alerts
        interval: 30s
        rules:
          - alert: HighErrorRate
            expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "High error rate detected"
              description: "Error rate is {{ $value }} for {{ $labels.instance }}"

          - alert: HighLatency
            expr: histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m])) > 1
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High latency detected"
              description: "P99 latency is {{ $value }}s for {{ $labels.instance }}"

          - alert: PodCrashLooping
            expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "Pod is crash looping"
              description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is crash looping"

          - alert: HighMemoryUsage
            expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes > 0.9
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High memory usage"
              description: "Memory usage is {{ $value | humanizePercentage }} on {{ $labels.instance }}"

          - alert: HighCPUUsage
            expr: 100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "High CPU usage"
              description: "CPU usage is {{ $value }}% on {{ $labels.instance }}"

          - alert: DiskSpaceLow
            expr: (node_filesystem_avail_bytes / node_filesystem_size_bytes) < 0.1
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "Low disk space"
              description: "Disk space is below 10% on {{ $labels.instance }}"

          - alert: PostgreSQLDown
            expr: up{job="postgres"} == 0
            for: 1m
            labels:
              severity: critical
            annotations:
              summary: "PostgreSQL is down"
              description: "PostgreSQL instance {{ $labels.instance }} is down"

          - alert: RedisDown
            expr: up{job="redis"} == 0
            for: 1m
            labels:
              severity: critical
            annotations:
              summary: "Redis is down"
              description: "Redis instance {{ $labels.instance }} is down"
